{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/results?search_query=trailer+les+dents+de+la+mer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deepface import DeepFace\n",
    "from deepface.detectors import FaceDetector\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bechdel_df = pd.read_json('../bechdel_data.json')\n",
    "imdb_df = pd.read_json('../tmdb_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df['imdb_id'] = imdb_df['imdb_id'].apply(lambda x: x[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(bechdel_df,imdb_df,left_on='imdbid', right_on='imdb_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df = merged_df[['rating','overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = tf.keras.utils.to_categorical(nlp_df[\"rating\"].values, num_classes=4)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(nlp_df['overview'], y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Deleting lock file /var/folders/tw/0_4t24xd3vs3yb_2z5jssqnc0000gn/T/tfhub_modules/0b208fb1aede71e39af87c9b138eacb4c72ce1cd.lock due to inactivity.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "preprocessor = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\")\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-base/1\")\n",
    "\n",
    "\n",
    "def get_embeddings(sentences):\n",
    "  '''return BERT-like embeddings of input text\n",
    "  Args:\n",
    "    - sentences: list of strings\n",
    "  Output:\n",
    "    - BERT-like embeddings: tf.Tensor of shape=(len(sentences), 768)\n",
    "  '''\n",
    "  preprocessed_text = preprocessor(sentences)\n",
    "  return encoder(preprocessed_text)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def plot_similarity(features, labels):\n",
    "  \"\"\"Plot a similarity matrix of the embeddings.\"\"\"\n",
    "  cos_sim = cosine_similarity(features)\n",
    "  fig = plt.figure(figsize=(10,8))\n",
    "  sns.set(font_scale=1.2)\n",
    "  cbar_kws=dict(use_gridspec=False, location=\"left\")\n",
    "  g = sns.heatmap(\n",
    "      cos_sim, xticklabels=labels, yticklabels=labels,\n",
    "      vmin=0, vmax=1, annot=True, cmap=\"Blues\", \n",
    "      cbar_kws=cbar_kws)\n",
    "  g.tick_params(labelright=True, labelleft=False)\n",
    "  g.set_yticklabels(labels, rotation=0)\n",
    "  g.set_title(\"Semantic Textual Similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity(get_embeddings(x_train), x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def balanced_recall(y_true, y_pred):\n",
    "    \"\"\"This function calculates the balanced recall metric\n",
    "    recall = TP / (TP + FN)\n",
    "    \"\"\"\n",
    "    recall_by_class = 0\n",
    "    # iterate over each predicted class to get class-specific metric\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        y_true_class = y_true[:, i]\n",
    "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true_class, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        recall_by_class = recall_by_class + recall\n",
    "    return recall_by_class / y_pred.shape[1]\n",
    "\n",
    "def balanced_precision(y_true, y_pred):\n",
    "    \"\"\"This function calculates the balanced precision metric\n",
    "    precision = TP / (TP + FP)\n",
    "    \"\"\"\n",
    "    precision_by_class = 0\n",
    "    # iterate over each predicted class to get class-specific metric\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        y_true_class = y_true[:, i]\n",
    "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred_class, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        precision_by_class = precision_by_class + precision\n",
    "    # return average balanced metric for each class\n",
    "    return precision_by_class / y_pred.shape[1]\n",
    "\n",
    "def balanced_f1_score(y_true, y_pred):\n",
    "    \"\"\"This function calculates the F1 score metric\"\"\"\n",
    "    precision = balanced_precision(y_true, y_pred)\n",
    "    recall = balanced_recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "x = preprocessor(i)\n",
    "x = encoder(x)\n",
    "x = tf.keras.layers.Dropout(0.2, name=\"dropout\")(x['pooled_output'])\n",
    "x = tf.keras.layers.Dense(4, activation='softmax', name=\"output\")(x)\n",
    "\n",
    "model = tf.keras.Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "196/196 [==============================] - 1252s 6s/step - loss: 1.0923 - accuracy: 0.5658 - balanced_recall: 0.2005 - balanced_precision: 0.2196 - balanced_f1_score: 0.2018 - val_loss: 1.0047 - val_accuracy: 0.5942 - val_balanced_recall: 0.2194 - val_balanced_precision: 0.2485 - val_balanced_f1_score: 0.2272\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 1106s 6s/step - loss: 1.0030 - accuracy: 0.5936 - balanced_recall: 0.2173 - balanced_precision: 0.2703 - balanced_f1_score: 0.2347 - val_loss: 0.9850 - val_accuracy: 0.6034 - val_balanced_recall: 0.2323 - val_balanced_precision: 0.2437 - val_balanced_f1_score: 0.2316\n",
      "Epoch 3/20\n",
      " 91/196 [============>.................] - ETA: 7:46 - loss: 0.9561 - accuracy: 0.6130 - balanced_recall: 0.2440 - balanced_precision: 0.3297 - balanced_f1_score: 0.2755"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "      balanced_recall,\n",
    "      balanced_precision,\n",
    "      balanced_f1_score\n",
    "]\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
    "                                                      patience = 3,\n",
    "                                                      restore_best_weights = True)\n",
    "\n",
    "model.compile(optimizer = \"adam\",\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = METRICS)\n",
    "\n",
    "model_fit = model.fit(x_train, \n",
    "                      y_train, \n",
    "                      epochs = n_epochs,\n",
    "                      validation_data = (x_test, y_test),\n",
    "                      callbacks = [earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1, n_epochs+1))\n",
    "metric_list = list(model_fit.history.keys())\n",
    "num_metrics = int(len(metric_list)/2)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=num_metrics, figsize=(30, 5))\n",
    "\n",
    "for i in range(0, num_metrics):\n",
    "  ax[i].plot(x, model_fit.history[metric_list[i]], marker=\"o\", label=metric_list[i].replace(\"_\", \" \"))\n",
    "  ax[i].plot(x, model_fit.history[metric_list[i+num_metrics]], marker=\"o\", label=metric_list[i+num_metrics].replace(\"_\", \" \"))\n",
    "  ax[i].set_xlabel(\"epochs\",fontsize=14)\n",
    "  ax[i].set_title(metric_list[i].replace(\"_\", \" \"),fontsize=20)\n",
    "  ax[i].legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a06b16eeb1aafe456feb02fe6e0b1401b216a035170a1a7613df3d99ddf6e3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hackathon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
